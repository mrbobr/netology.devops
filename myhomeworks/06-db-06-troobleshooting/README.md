# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
> 1. Для поиска CRUD операций в mongo-shell используется метод `currentOp`. Для поиска и первичного анализа выполним запрос c применением метода aggregate и настроенным шаблоном для вывода:
 ```
 > use admin
 > db.aggregate( [    { $currentOp : { allUsers: true, idleConnections: false } }, { $match : { secs_running: {$gt: 180} }}, { $project: { _id:0, currentOpTime: 1, opid:1, host:1, op:1, secs_running: 1, waitingForLock: 1, numYields: 1, effectiveUsers: 1  } } ] ).pretty() 
 ```
> Получим список операций, длящихся более 180 секунд. Пример вывода операции:
```
"host" : "7a7c09046d7b:27017",
"currentOpTime" : "2022-05-15T20:52:32.328+00:00",    
"opid" : 22743,
"lsid" : {
        "id" : UUID("181876ee-e426-414f-a746-4a06c8c23cab"),
        "uid" : BinData(0,"47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=")
	  },
"secs_running" : NumberLong(335),
"op" : "update",
"numYields" : 10,
"waitingForLock" : false
```
> Если в выводе будет несколько операций, то можно добавить в фильтр другие условия. Например, уточнить у пользователя, что конкретно за операция выполнялась и добавить в фильтр $match : {op: "операция"}.  
> После однозначной идентификации операции её можно "убить" методом killOp(opid). В случае с шардированым кластером для прерывания операций записи, удобнее использовать метод killSessions(lsid), иначе нужно будет выполнить killOp для каждого шарда.
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB
> Если выполняемая операция не ожидает снятия блокировок или получения данных, то для анализа плана выполнения запроса можно использовать на нём метод explain("executionStats").  
> Скорее всего для ускорения выполнения запроса необходимо будет создать или перестроить индексы.  
> Если операция не выполняется из-за блокировок (waitingForLock : true), то необходимо определить причины блокировок из вывода currentOP и связаться с разработчиком для их устранения.  
> Причинами ожидания операцией получения данных (numYelds больше 0) могут быть слишком большое количество получаемых / записываемых данных, отсутствие индексов, недостаточное количество RAM. Соответственно, можно попробовать увеличить кол-во RAM, либо рекомендовать разработчику создать индексы и/или разбить операцию на операции с использованием меньшего количества данных. 
## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?
> Проблема, вероятно, заключается в особенностях работы алгоритма активного удаления истекших ключей.  
> 10 раз в секунду redis проверяет случайный набор из 20 ключей и если находит среди них истекшие - выполняет их удаление. Если же в наборе уже истекших ключей более 25%, то операция повторяется. Возникает ситуация когда уже истекших ключей в течение одной секунды (истекающих в одну и ту же секунду) может быть постоянно более 25% от набора. В этом случае операция зацикливается и redis может блокировать операции записи для достижения числа уже истекших ключей ниже 25%.  
> Увеличив количество реплик сервиса, мы по условию получили увеличение количества записываемых значений, но и одновременно увеличили вероятность возникновения в БД большего количества одновременно истекших ключей.
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?
> Возросла нагрузка на СУБД из-за большего количества данных отдаваемого в запросах. Соединение прерывается по таймауту до завершения чтения.
> Сопутствующей причиной может быть невозможность подключения в период высокой нагрузки.

Какие пути решения данной проблемы вы можете предложить?
> 1. Увеличить таймаут для чтения данных (параметр net_read_timeout, по умолчанию равен 30сек), либо увеличить таймаут подключения connect_timeout.
> 2. Посмотреть план запроса для оптимизации. По результатам, например, создать индекс(ы), либо разбить запрос на несколько.
> 3. Увеличить ресурсы сервера СУБД

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?
> Такая ошибка возникает при нехватке памяти на сервере. Для избежания "падения" всей системы ОС завершает процесс, послуживший причиной нехватки.

Как бы вы решили данную проблему?
> Попробовать решить проблему можно двумя путями:
> 1. Увеличить объем RAM на сервере.
> 2. Настроить в конфигурационном файле postgresql.conf параметры использования памяти:  
>   shared_buffer + max_wal_size, temp_buffers, work_mem, effective_cache_size
---
